{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import evaluation_utils.eval_grouping_queries as queries\n",
    "from evaluation_utils.plotting_utils import *\n",
    "import evaluation_utils.exploration_utils as data_manip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_avg_stats_split_easy(result_dir, \n",
    "                             data_files, \n",
    "                             config_dir, \n",
    "                             config_files, \n",
    "                             option=0, \n",
    "                             stat=\"avg_binary_score\", \n",
    "                             mode=1):\n",
    "    data = []\n",
    "\n",
    "    for file in data_files:\n",
    "        full_path = result_dir + file\n",
    "        data.append(pd.read_csv(full_path))\n",
    "\n",
    "    configs = []\n",
    "\n",
    "    for file in config_files:\n",
    "        full_path = config_dir + file\n",
    "        with open(full_path) as f:\n",
    "            configs.append(json.load(f))\n",
    "    \n",
    "    for i, d in enumerate(data):\n",
    "        if mode == 1:\n",
    "            d = d[d[\"perturbation\"] == \"original\"]\n",
    "        else:\n",
    "            d = d[d[\"perturbation\"] == \"negation\"]\n",
    "        \n",
    "        data[i] = d\n",
    "    \n",
    "    avg_total = 0\n",
    "    for i in range(len(data)):\n",
    "        avg_total += data[i][stat].sum()\n",
    "    \n",
    "    total = 0\n",
    "    for i in range(len(data)):\n",
    "        total += len(data[i])\n",
    "    \n",
    "    avg = avg_total / total\n",
    "    \n",
    "    more = []\n",
    "    less = []\n",
    "    for i in range(len(data)):\n",
    "        tup = data_manip.filter_data_into_more_less_by_actual_comparison(data[i],\n",
    "                                                                         configs[i],\n",
    "                                                                         option=option)\n",
    "        more.append(tup[0])\n",
    "        less.append(tup[1])\n",
    "    \n",
    "    more_avg_total = 0\n",
    "    less_avg_total = 0\n",
    "    for i in range(len(more)):\n",
    "        more_avg_total += more[i][stat].sum()\n",
    "        less_avg_total += less[i][stat].sum()\n",
    "    \n",
    "    more_total = 0\n",
    "    less_total = 0\n",
    "    for i in range(len(more)):\n",
    "        more_total += len(more[i])\n",
    "        less_total += len(less[i])\n",
    "    \n",
    "    \n",
    "    more_avg = more_avg_total / more_total\n",
    "    less_avg = less_avg_total / less_total\n",
    "    \n",
    "    return (str(total), str(round(avg, 3)), str(round(more_avg, 3)), str(round(less_avg, 3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_avg_stats(result_dir, data_files, config_dir, config_files, option=0, stat=\"avg_binary_score\"):\n",
    "    data = []\n",
    "\n",
    "    for file in data_files:\n",
    "        full_path = result_dir + file\n",
    "        data.append(pd.read_csv(full_path))\n",
    "\n",
    "    configs = []\n",
    "\n",
    "    for file in config_files:\n",
    "        full_path = config_dir + file\n",
    "        with open(full_path) as f:\n",
    "            configs.append(json.load(f))\n",
    "    \n",
    "    avg_total = 0\n",
    "    for i in range(len(data)):\n",
    "        avg_total += data[i][stat].sum()\n",
    "    \n",
    "    total = 0\n",
    "    for i in range(len(data)):\n",
    "        total += len(data[i])\n",
    "    \n",
    "    avg = avg_total / total\n",
    "    \n",
    "    more = []\n",
    "    less = []\n",
    "    for i in range(len(data)):\n",
    "        tup = data_manip.filter_data_into_more_less_by_actual_comparison(data[i],\n",
    "                                                                         configs[i],\n",
    "                                                                         option=option)\n",
    "        more.append(tup[0])\n",
    "        less.append(tup[1])\n",
    "    \n",
    "    more_avg_total = 0\n",
    "    less_avg_total = 0\n",
    "    for i in range(len(more)):\n",
    "        more_avg_total += more[i][stat].sum()\n",
    "        less_avg_total += less[i][stat].sum()\n",
    "    \n",
    "    more_total = 0\n",
    "    less_total = 0\n",
    "    for i in range(len(more)):\n",
    "        more_total += len(more[i])\n",
    "        less_total += len(less[i])\n",
    "    \n",
    "    \n",
    "    more_avg = more_avg_total / more_total\n",
    "    less_avg = less_avg_total / less_total\n",
    "    \n",
    "    return (str(total), str(round(avg, 3)), str(round(more_avg, 3)), str(round(less_avg, 3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict = {\n",
    "    \"Task\" : [],\n",
    "    \"Model-Setting\" : [],\n",
    "    \"Dataset Size\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"'More' Accuracy\" : [],\n",
    "    \"'Less' Accuracy\" : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROBERTA MWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta-base/\"\n",
    "\n",
    "data_files = [\"material_perf_2_10.csv\", \"physical_perf_2_10.csv\", \"social_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files, stat='avg_ratio_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '-0.003', '0.56', '-0.565')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MWP ROBERTA Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"material_perf_ft_10.csv\", \"physical_perf_ft_10.csv\", \"social_perf_ft_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Fine Tuned\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MWP ROBERTA Just Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"social_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Just Social\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MWP ROBERTA Abalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta_w_name/\"\n",
    "\n",
    "data_files = [\"social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Social w names\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MWP ROBERTA Easy - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta_easy/\"\n",
    "\n",
    "data_files = [\"easy_material_perf_10.csv\", \n",
    "              \"easy_physical_perf_10.csv\",\n",
    "              \"easy_social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats_split_easy(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Easy, No Switch\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MWP ROBERTA Easy - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta_easy/\"\n",
    "\n",
    "data_files = [\"easy_material_perf_10.csv\", \n",
    "              \"easy_physical_perf_10.csv\",\n",
    "              \"easy_social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats_split_easy(result_dir, data_files, config_dir, config_files, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Easy, Negation Switch\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MWP ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/albert/\"\n",
    "\n",
    "data_files = [\"albert_material_perf_2_10.csv\", \n",
    "              \"albert_physical_perf_2_10.csv\",\n",
    "              \"albert_social_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"ALBERT\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entailment RoBERTa - Entailment Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"material_entail_perf_2_10.csv\", \n",
    "              \"physical_entail_perf_2_10.csv\",\n",
    "              \"social_entail_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '0.183', '0.168', '0.197')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Entailment,Contradiction\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[3], tup_2[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entailment RoBERTa - social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"social_entail_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Just Social\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[3], tup_2[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entailment RoBERTa - w Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/roberta_w_name/\"\n",
    "\n",
    "data_files = [\"social_entail_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Social w Name\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[3], tup_2[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entailment BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/bart/\"\n",
    "\n",
    "data_files = [\"material_entail_perf_10.csv\", \"physical_entail_perf_10.csv\", \"social_entail_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '0.089', '0.075', '0.102')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"BART\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[3], tup_2[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generative GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '0.493', '0.777', '0.209')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dir = \"../data/generation_result_data/gpt2/\"\n",
    "\n",
    "data_files = [\"material_perf_10.csv\", \"physical_perf_10.csv\", \"social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '-0.0', '0.034', '-0.034')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files, stat='avg_ratio_score')\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Generative\")\n",
    "output_dict[\"Model-Setting\"].append(\"GPT2\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generative COMET-ConecptNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '0.496', '0.698', '0.294')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dir = \"../data/generation_result_data/comet_conceptnet/\"\n",
    "\n",
    "data_files = [\"material_perf_10.csv\", \"physical_perf_10.csv\", \"social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '0.0', '0.037', '-0.036')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files, stat='avg_ratio_score')\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Generative\")\n",
    "output_dict[\"Model-Setting\"].append(\"COMET-ConceptNet\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '0.498', '0.664', '0.332')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generative COMET-ATOMIC\n",
    "\n",
    "result_dir = \"../data/generation_result_data/comet_atomic/\"\n",
    "\n",
    "data_files = [\"material_perf_10.csv\", \"physical_perf_10.csv\", \"social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1440', '-0.0', '0.023', '-0.023')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files, stat='avg_ratio_score')\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Generative\")\n",
    "output_dict[\"Model-Setting\"].append(\"COMET-ATOMIC\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Human\")\n",
    "output_dict[\"Model-Setting\"].append(\"Human-20 Responses\")\n",
    "output_dict[\"Dataset Size\"].append(\"72\")\n",
    "output_dict[\"Accuracy\"].append(\"0.845\")\n",
    "output_dict[\"'More' Accuracy\"].append(\"0.831\")\n",
    "output_dict[\"'Less' Accuracy\"].append(\"0.863\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "       Task &                     Model-Setting & Dataset Size &      Accuracy & 'More' Accuracy & 'Less' Accuracy \\\\\n",
      "\\midrule\n",
      "        MWP &                           RoBERTa &         1440 &          0.51 &           0.899 &           0.122 \\\\\n",
      "        MWP &                RoBERTa-Fine Tuned &          144 &         0.467 &           0.775 &           0.158 \\\\\n",
      "        MWP &               RoBERTa-Just Social &          480 &          0.51 &            0.81 &            0.21 \\\\\n",
      "        MWP &            RoBERTa-Social w names &          480 &         0.517 &           0.825 &           0.208 \\\\\n",
      "        MWP &           RoBERTa-Easy, No Switch &           60 &         0.925 &             1.0 &            0.85 \\\\\n",
      "        MWP &     RoBERTa-Easy, Negation Switch &           60 &         0.358 &           0.517 &             0.2 \\\\\n",
      "        MWP &                            ALBERT &         1440 &          0.49 &           0.734 &           0.246 \\\\\n",
      " Entailment &  RoBERTa-Entailment,Contradiction &         1440 &   0.05, 0.183 &    0.054, 0.168 &    0.046, 0.197 \\\\\n",
      " Entailment &               RoBERTa-Just Social &          480 &  0.107, 0.281 &    0.106, 0.258 &    0.108, 0.304 \\\\\n",
      " Entailment &             RoBERTa-Social w Name &          480 &  0.126, 0.286 &    0.129, 0.279 &    0.123, 0.293 \\\\\n",
      " Entailment &                              BART &         1440 &    0.1, 0.089 &    0.107, 0.075 &    0.093, 0.102 \\\\\n",
      " Generative &                              GPT2 &         1440 &         0.493 &           0.777 &           0.209 \\\\\n",
      "      Human &                Human-20 Responses &           72 &         0.845 &           0.831 &           0.863 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
