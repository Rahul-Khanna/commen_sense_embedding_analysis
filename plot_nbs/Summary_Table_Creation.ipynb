{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation_utils.eval_grouping_queries as queries\n",
    "from evaluation_utils.plotting_utils import *\n",
    "import evaluation_utils.exploration_utils as data_manip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_stats(result_dir, data_files, config_dir, config_files, option=0, stat=\"avg_binary_score\"):\n",
    "    data = []\n",
    "\n",
    "    for file in data_files:\n",
    "        full_path = result_dir + file\n",
    "        data.append(pd.read_csv(full_path))\n",
    "\n",
    "    configs = []\n",
    "\n",
    "    for file in config_files:\n",
    "        full_path = config_dir + file\n",
    "        with open(full_path) as f:\n",
    "            configs.append(json.load(f))\n",
    "    \n",
    "    avg_total = 0\n",
    "    for i in range(len(data)):\n",
    "        avg_total += data[i][stat].sum()\n",
    "    \n",
    "    total = 0\n",
    "    for i in range(len(data)):\n",
    "        total += len(data[i])\n",
    "    \n",
    "    avg = avg_total / total\n",
    "    \n",
    "    more = []\n",
    "    less = []\n",
    "    for i in range(len(data)):\n",
    "        tup = data_manip.filter_data_into_more_less_by_actual_comparison(data[i],\n",
    "                                                                         configs[i],\n",
    "                                                                         option=option)\n",
    "        more.append(tup[0])\n",
    "        less.append(tup[1])\n",
    "    \n",
    "    more_avg_total = 0\n",
    "    less_avg_total = 0\n",
    "    for i in range(len(more)):\n",
    "        more_avg_total += more[i][stat].sum()\n",
    "        less_avg_total += less[i][stat].sum()\n",
    "    \n",
    "    more_total = 0\n",
    "    less_total = 0\n",
    "    for i in range(len(more)):\n",
    "        more_total += len(more[i])\n",
    "        less_total += len(less[i])\n",
    "    \n",
    "    \n",
    "    more_avg = more_avg_total / more_total\n",
    "    less_avg = less_avg_total / less_total\n",
    "    \n",
    "    return (str(total), str(round(avg, 3)), str(round(more_avg, 3)), str(round(less_avg, 3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\n",
    "    \"Task\" : [],\n",
    "    \"Model-Setting\" : [],\n",
    "    \"Dataset Size\" : [],\n",
    "    \"Accuracy\" : [],\n",
    "    \"'More' Accuracy\" : [],\n",
    "    \"'Less' Accuracy\" : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROBERTA MWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"material_perf_2_10.csv\", \"physical_perf_2_10.csv\", \"social_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MWP ROBERTA Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"material_perf_ft_10.csv\", \"physical_perf_ft_10.csv\", \"social_perf_ft_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Fine Tuned\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MWP ROBERTA Just Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"social_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Just Social\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MWP ROBERTA Abalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta_w_name/\"\n",
    "\n",
    "data_files = [\"social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Social w names\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MWP ROBERTA Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/roberta_easy/\"\n",
    "\n",
    "data_files = [\"easy_material_perf_10.csv\", \n",
    "              \"easy_physical_perf_10.csv\",\n",
    "              \"easy_social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Easy\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MWP ALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/masked_word_result_data/albert/\"\n",
    "\n",
    "data_files = [\"albert_material_perf_2_10.csv\", \n",
    "              \"albert_physical_perf_2_10.csv\",\n",
    "              \"albert_social_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"MWP\")\n",
    "output_dict[\"Model-Setting\"].append(\"ALBERT\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entailment RoBERTa - Entailment Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"material_entail_perf_2_10.csv\", \n",
    "              \"physical_entail_perf_2_10.csv\",\n",
    "              \"social_entail_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Entailment,Contradiction\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entailment RoBERTa - social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/roberta/\"\n",
    "\n",
    "data_files = [\"social_entail_perf_2_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Just Social\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entailment RoBERTa - w Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/roberta_w_name/\"\n",
    "\n",
    "data_files = [\"social_entail_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"RoBERTa-Social w Name\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entailment BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/entailment_result_data/bart/\"\n",
    "\n",
    "data_files = [\"material_entail_perf_10.csv\", \"physical_entail_perf_10.csv\", \"social_entail_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup_1 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"ent_avg_score\")\n",
    "tup_2 = get_avg_stats(result_dir, data_files, config_dir, config_files, \n",
    "                    option=1, stat=\"contr_avg_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Entailment\")\n",
    "output_dict[\"Model-Setting\"].append(\"BART\")\n",
    "output_dict[\"Dataset Size\"].append(tup_1[0])\n",
    "output_dict[\"Accuracy\"].append(\"{}, {}\".format(tup_1[1], tup_2[1]))\n",
    "output_dict[\"'More' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))\n",
    "output_dict[\"'Less' Accuracy\"].append(\"{}, {}\".format(tup_1[2], tup_2[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"../data/generation_result_data/gpt2/\"\n",
    "\n",
    "data_files = [\"material_perf_10.csv\", \"physical_perf_10.csv\", \"social_perf_10.csv\"]\n",
    "\n",
    "config_dir = \"../data/truism_data/\"\n",
    "\n",
    "config_files = [\"material_data_2.json\", \"physical_data_2.json\", \"social_data_2.json\"]\n",
    "\n",
    "tup = get_avg_stats(result_dir, data_files, config_dir, config_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Generative\")\n",
    "output_dict[\"Model-Setting\"].append(\"GPT2\")\n",
    "output_dict[\"Dataset Size\"].append(tup[0])\n",
    "output_dict[\"Accuracy\"].append(tup[1])\n",
    "output_dict[\"'More' Accuracy\"].append(tup[2])\n",
    "output_dict[\"'Less' Accuracy\"].append(tup[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict[\"Task\"].append(\"Human\")\n",
    "output_dict[\"Model-Setting\"].append(\"Human-18 Responses\")\n",
    "output_dict[\"Dataset Size\"].append(\"72\")\n",
    "output_dict[\"Accuracy\"].append(\"0.869\")\n",
    "output_dict[\"'More' Accuracy\"].append(\"\")\n",
    "output_dict[\"'Less' Accuracy\"].append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "       Task &                     Model-Setting & Dataset Size &      Accuracy & 'More' Accuracy & 'Less' Accuracy \\\\\n",
      "\\midrule\n",
      "        MWP &                           RoBERTa &         1440 &          0.51 &           0.899 &           0.122 \\\\\n",
      "        MWP &                RoBERTa-Fine Tuned &          144 &         0.467 &           0.775 &           0.158 \\\\\n",
      "        MWP &               RoBERTa-Just Social &          480 &          0.51 &            0.81 &            0.21 \\\\\n",
      "        MWP &            RoBERTa-Social w names &          480 &         0.517 &           0.825 &           0.208 \\\\\n",
      "        MWP &                      RoBERTa-Easy &           60 &          0.93 &             1.0 &            0.86 \\\\\n",
      "        MWP &                            ALBERT &         1440 &          0.49 &           0.734 &           0.246 \\\\\n",
      " Entailment &  RoBERTa-Entailment,Contradiction &         1440 &   0.05, 0.183 &    0.054, 0.168 &    0.054, 0.168 \\\\\n",
      " Entailment &               RoBERTa-Just Social &          480 &  0.107, 0.281 &    0.106, 0.258 &    0.106, 0.258 \\\\\n",
      " Entailment &             RoBERTa-Social w Name &          480 &  0.126, 0.286 &    0.129, 0.279 &    0.129, 0.279 \\\\\n",
      " Entailment &                              BART &         1440 &    0.1, 0.089 &    0.107, 0.075 &    0.107, 0.075 \\\\\n",
      " Generative &                              GPT2 &         1440 &         0.493 &           0.777 &           0.209 \\\\\n",
      "      Human &                Human-18 Responses &           72 &         0.869 &                 &                 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
